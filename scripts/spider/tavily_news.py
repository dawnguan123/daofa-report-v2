#!/usr/bin/env python3
"""
æ—¶æ”¿æ–°é—»è·å–å™¨ - Tavily API ç‰ˆ
ä½¿ç”¨ Tavily AI æœç´¢å¼•æ“è·å–æ—¶æ”¿æ–°é—»
"""
import os
import re
from datetime import datetime
from tavily import TavilyClient

# API Key (ç”¨æˆ·æä¾›çš„)
TAVILY_API_KEY = "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"


class TavilyNewsFetcher:
    """åŸºäº Tavily çš„æ—¶æ”¿æ–°é—»è·å–å™¨"""
    
    def __init__(self, api_key=None):
        self.api_key = api_key or TAVILY_API_KEY
        self.client = TavilyClient(api_key=self.api_key)
    
    def search_news(self, query, max_results=10):
        """æœç´¢æ–°é—»"""
        try:
            response = self.client.search(
                query=query,
                max_results=max_results,
                include_answer=True,
                include_raw_content=False
            )
            return response.get('results', [])
        except Exception as e:
            print(f"  æœç´¢é”™è¯¯: {e}")
            return []
    
    def fetch_content(self, url):
        """è·å–ç½‘é¡µå†…å®¹"""
        try:
            response = self.client.fetch_content(url=url)
            return response.get('content', '')
        except Exception as e:
            print(f"  è·å–å†…å®¹é”™è¯¯: {e}")
            return ''
    
    def enrich_news(self, search_result):
        """ä¸°å¯Œæ–°é—»å†…å®¹"""
        url = search_result.get('url', '')
        title = search_result.get('title', '')
        answer = search_result.get('answer', '')
        
        # ä½¿ç”¨ search å·²è¿”å›çš„å†…å®¹
        content = search_result.get('content', '') or answer
        
        # æå–å…³é”®è¦ç‚¹
        key_points = self._extract_key_points(content, title)
        
        # ç”Ÿæˆæ‘˜è¦
        summary = self._generate_summary(content, answer)
        
        return {
            'title': title,
            'url': url,
            'source': self._guess_source(url),
            'time': datetime.now().strftime('%Y-%m-%d %H:%M'),
            'category': self._guess_category(title),
            'content': content,
            'summary': summary,
            'key_points': key_points
        }
    
    def _extract_key_points(self, content, title):
        """æå–å…³é”®è¦ç‚¹"""
        key_points = []
        
        if not content:
            return []
        
        # æå–äººå
        names = re.findall(r'ä¹ è¿‘å¹³|æå¼º|ä¸è–›ç¥¥|æå¸Œ|ç‹æ¯…|èµµä¹é™…', content)
        if names:
            key_points.append(f"æ¶‰åŠäººç‰©ï¼š{', '.join(set(names[:2]))}")
        
        # æå–æœºæ„
        orgs = re.findall(r'ä¸­å…±ä¸­å¤®|å›½åŠ¡é™¢|ä¸­å¤®å†›å§”|å›½å°åŠ|å·¥ä¿¡éƒ¨|ç§‘æŠ€éƒ¨|æ•™è‚²éƒ¨|å¸‚åœºç›‘ç®¡æ€»å±€', content)
        if orgs:
            key_points.append(f"æ¶‰åŠæœºæ„ï¼š{', '.join(set(orgs[:2]))}")
        
        # æå–å…³é”®äº‹ä»¶
        events = re.findall(r'(æœˆçƒæ¢æµ‹|è½½äººèˆªå¤©|åè…è´¥|ä¸¤å²¸|å»ºå†›|æ”¹é©|å‘å±•|ç§‘æŠ€è‡ªç«‹è‡ªå¼º)', content)
        if events:
            key_points.append(f"å…³é”®äº‹ä»¶ï¼š{', '.join(set(events[:2]))}")
        
        # æå–æ—¶é—´
        dates = re.findall(r'(\d+å¹´\d+æœˆ\d+æ—¥|\d+æœˆ\d+æ—¥)', content)
        if dates:
            key_points.append(f"æ—¶é—´ï¼š{dates[0]}")
        
        return key_points
    
    def _generate_summary(self, content, answer):
        """ç”Ÿæˆæ‘˜è¦"""
        # å¦‚æœæœ‰ Tavily çš„ answerï¼Œç›´æ¥ä½¿ç”¨
        if answer and len(answer) > 50:
            return answer[:300] + ("..." if len(answer) > 300 else "")
        
        # å¦åˆ™ä»å†…å®¹æˆªå–
        if content:
            return content[:300] + ("..." if len(content) > 300 else "")
        
        return ""
    
    def _guess_category(self, title):
        """çŒœæµ‹åˆ†ç±»"""
        title_lower = title.lower()
        
        categories = {
            'æ•™è‚²': ['æ•™è‚²', 'å­¦æ ¡', 'å­¦ç”Ÿ', 'æ•™å¸ˆ', 'è€ƒè¯•'],
            'æ³•å¾‹': ['æ³•å¾‹', 'æ³•é™¢', 'æ£€å¯Ÿ', 'å¸æ³•', 'çŠ¯ç½ª', 'æœªæˆå¹´'],
            'ç»æµ': ['ç»æµ', 'GDP', 'CPI', 'ç»Ÿè®¡å±€', 'å¸‚åœº', 'æ¶ˆè´¹', 'äº§ä¸š'],
            'æ”¿æ²»': ['ä¹ è¿‘å¹³', 'æå¼º', 'ä¼šè®®', 'è®²è¯', 'å…šå»º', 'å†›é˜Ÿ', 'å»ºå†›', 'ä¸­å…±ä¸­å¤®'],
            'ç¤¾ä¼š': ['ç¤¾ä¼š', 'æ°‘ç”Ÿ', 'åŒ»ç–—', 'ç¤¾ä¿', 'å°±ä¸š', 'ä½æˆ¿'],
            'ç§‘æŠ€': ['ç§‘æŠ€', 'èˆªå¤©', 'æœˆçƒ', 'AI', 'åˆ›æ–°', 'è‡ªç«‹è‡ªå¼º'],
            'ä¸¤å²¸': ['å°æ¹¾', 'ä¸¤å²¸', 'å›½å°åŠ', 'å°æµ·', 'ç»Ÿä¸€'],
            'å¤–äº¤': ['å¤–äº¤', 'å¤–é•¿', 'è”åˆå›½', 'å›½é™…', 'å³°ä¼š']
        }
        
        for cat, keywords in categories.items():
            for kw in keywords:
                if kw in title:
                    return cat
        
        return 'æ—¶æ”¿'
    
    def _guess_source(self, url):
        """çŒœæµ‹æ¥æº"""
        if 'sina' in url:
            return 'æ–°æµªæ–°é—»'
        elif 'qq' in url:
            return 'è…¾è®¯æ–°é—»'
        elif 'ifeng' in url:
            return 'å‡¤å‡°æ–°é—»'
        elif 'people' in url:
            return 'äººæ°‘ç½‘'
        elif 'xinhuanet' in url:
            return 'æ–°åç½‘'
        elif 'chinanews' in url:
            return 'ä¸­å›½æ–°é—»ç½‘'
        elif 'inewsweek' in url:
            return 'ä¸­å›½æ–°é—»å‘¨åˆŠ'
        elif 'moe' in url:
            return 'æ•™è‚²éƒ¨'
        else:
            return 'å…¶ä»–åª’ä½“'
    
    def get_political_news(self, max_news=5):
        """è·å–æ—¶æ”¿æ–°é—»ä¸»å…¥å£"""
        print("ğŸ” ä½¿ç”¨ Tavily æœç´¢æ—¶æ”¿æ–°é—»...")
        
        # æœç´¢ç­–ç•¥
        queries = [
            "2026å¹´2æœˆ ä¸­å›½æ—¶æ”¿æ–°é—» ä¹ è¿‘å¹³",
            "2026å¹´2æœˆ ä¸­å›½æ”¿åºœ å›½åŠ¡é™¢", 
            "2026å¹´2æœˆ ä¸­å›½ä¸¤ä¼š æ”¿ç­–"
        ]
        
        all_results = []
        
        for query in queries[:2]:  # åªæœç´¢å‰2ä¸ª
            print(f"  ğŸ“° æœç´¢: {query[:30]}...")
            results = self.search_news(query, max_results=5)
            all_results.extend(results)
            print(f"     è·å– {len(results)} æ¡ç»“æœ")
        
        # å»é‡
        seen_urls = set()
        unique_results = []
        for r in all_results:
            url = r.get('url', '')
            if url and url not in seen_urls:
                seen_urls.add(url)
                unique_results.append(r)
        
        print(f"\n  ğŸ“Š å»é‡å: {len(unique_results)} æ¡")
        
        # ä¸°å¯Œå†…å®¹
        news_list = []
        for i, result in enumerate(unique_results[:max_news], 1):
            print(f"  [{i}] ä¸°å¯Œå†…å®¹: {result.get('title', '')[:30]}...")
            enriched = self.enrich_news(result)
            news_list.append(enriched)
        
        return news_list


def fetch_news():
    """ä¾¿æ·å‡½æ•°"""
    fetcher = TavilyNewsFetcher()
    return fetcher.get_political_news(max_news=5)


if __name__ == "__main__":
    news = fetch_news()
    
    print(f"\n{'='*60}")
    print(f"è·å–åˆ° {len(news)} æ¡æ—¶æ”¿æ–°é—»:")
    print('='*60)
    
    for i, n in enumerate(news, 1):
        print(f"\n{i}. {n['title']}")
        print(f"   æ¥æº: {n['source']} | åˆ†ç±»: {n['category']}")
        if n['summary']:
            print(f"   æ‘˜è¦: {n['summary'][:80]}...")
        if n['key_points']:
            for p in n['key_points']:
                print(f"   â€¢ {p}")
