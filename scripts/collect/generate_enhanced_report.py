#!/usr/bin/env python3
"""
ç”Ÿæˆå¢å¼ºç‰ˆé“æ³•æ—¶äº‹æŠ¥å‘Š
- å®Œæ•´å†…å®¹
- æ€»ç»“é™ˆè¿°
- å…³é”®è¦ç‚¹
- è¯¾æœ¬å…³è”ï¼ˆå«ç›¸å…³åº¦æ‰“åˆ†ï¼‰
"""
import requests
import json
from bs4 import BeautifulSoup
from urllib.parse import urlparse
from datetime import datetime

INPUT_FILE = "/Users/guanliming/dailynews/output/hotnews_detail.json"
OUTPUT_FILE = "/Users/guanliming/dailynews/output/report_latest.html"
BASE_URL = "https://www.chinanews.com.cn"

# è¯¾æœ¬çŸ¥è¯†ç‚¹åº“ï¼ˆåŒ…å«æ ¸å¿ƒå†…å®¹ï¼‰
TEXTBOOK_DB = {
    'ä¸­åä¸€å®¶äº²': {
        'book': 'ä¹å¹´çº§ä¸Šå†Œ',
        'core': 'ç»´æŠ¤ç¥–å›½ç»Ÿä¸€ã€æ°‘æ—å›¢ç»“æ˜¯æ¯ä¸ªå…¬æ°‘çš„è´£ä»»å’Œä¹‰åŠ¡'
    },
    'æ°‘ä¸»ä¸æ³•æ²»': {
        'book': 'ä¹å¹´çº§ä¸Šå†Œ', 
        'core': 'ä¾æ³•æ²»å›½æ˜¯å…šé¢†å¯¼äººæ°‘æ²»ç†å›½å®¶çš„åŸºæœ¬æ–¹ç•¥'
    },
    'åˆ›æ–°é©±åŠ¨å‘å±•': {
        'book': 'ä¹å¹´çº§ä¸Šå†Œ',
        'core': 'åˆ›æ–°æ˜¯å¼•é¢†å‘å±•çš„ç¬¬ä¸€åŠ¨åŠ›'
    },
    'å»ºè®¾ç¾ä¸½ä¸­å›½': {
        'book': 'ä¹å¹´çº§ä¸Šå†Œ',
        'core': 'åšæŒäººä¸è‡ªç„¶å’Œè°å…±ç”Ÿï¼Œå»ºè®¾ç¾ä¸½ä¸­å›½'
    },
    'å¯Œå¼ºä¸åˆ›æ–°': {
        'book': 'ä¹å¹´çº§ä¸Šå†Œ',
        'core': 'ä»¥äººæ°‘ä¸ºä¸­å¿ƒï¼Œå®ç°å…±åŒå¯Œè£•'
    },
    'è¸ä¸Šå¼ºå›½ä¹‹è·¯': {
        'book': 'ä¹å¹´çº§ä¸Šå†Œ',
        'core': 'æ”¹é©å¼€æ”¾æ˜¯å†³å®šå½“ä»£ä¸­å›½å‘½è¿çš„å…³é”®ä¸€æ‹›'
    },
    'æ–‡æ˜ä¸å®¶å›­': {
        'book': 'ä¹å¹´çº§ä¸Šå†Œ',
        'core': 'ä¸­åä¼˜ç§€ä¼ ç»Ÿæ–‡åŒ–æ˜¯ä¸­åæ°‘æ—çš„ç²¾ç¥å‘½è„‰'
    },
    'ä¸­å›½äºº ä¸­å›½æ¢¦': {
        'book': 'ä¹å¹´çº§ä¸Šå†Œ',
        'core': 'å®ç°ä¸­åæ°‘æ—ä¼Ÿå¤§å¤å…´æ˜¯ä¸­åæ°‘æ—è¿‘ä»£ä»¥æ¥æœ€ä¼Ÿå¤§çš„æ¢¦æƒ³'
    },
}

def get_hot_rankings():
    """è·å–çƒ­æ¦œå‰10æ¡"""
    resp = requests.get(f"{BASE_URL}/importnews.html", timeout=15)
    resp.encoding = 'utf-8'
    soup = BeautifulSoup(resp.text, 'html.parser')
    
    hotbox = soup.find(id="zxrb")
    hot_urls = []
    if hotbox:
        next_list = hotbox.find_next_sibling()
        if next_list:
            for link in next_list.find_all('a')[:10]:
                href = link.get('href', '')
                if href:
                    if href.startswith('//'):
                        url = 'https:' + href
                    elif href.startswith('/'):
                        url = BASE_URL + href
                    else:
                        url = href
                    parsed = urlparse(url)
                    hot_urls.append(parsed.path)
    return hot_urls

def extract_key_points(content, title):
    """æå–å…³é”®è¦ç‚¹"""
    points = []
    
    # æ•°å­—ç±»ä¿¡æ¯
    nums = []
    for p in [r'(\d+\.\d+%)', r'(\d+ä¸‡)', r'(\d+äº¿)', r'(\d{4}å¹´)', r'(\d+)ä»¶', r'(\d+)äºº']:
        import re
        matches = re.findall(p, content)
        nums.extend([m for m in matches[:2]])
    
    if nums:
        points.append(f"ğŸ“Š æ•°æ®ï¼š{', '.join(nums[:2])}")
    
    # æœºæ„
    orgs = re.findall(r'([^\s]{2,6}(éƒ¨|å§”|å±€|åŠ|æ”¿åºœ))', content)
    for org in set([o[0] for o in orgs[:3]]):
        points.append(f"ğŸ›ï¸ æœºæ„ï¼š{org}")
    
    return points

def match_chapters(text):
    """åŒ¹é…è¯¾æœ¬ç« èŠ‚ï¼ˆè¿”å›ç›¸å…³åº¦ï¼‰"""
    rules = [
        {'kws': ['å°æ¹¾', 'ä¸¤å²¸', 'å°ç‹¬', 'å›½å°åŠ', 'å°æµ·', 'èµ–æ¸…å¾·'], 'chapter': 'ä¸­åä¸€å®¶äº²', 'score': 90},
        {'kws': ['åè…', 'è¿çºª', 'è¿æ³•', 'å—è´¿', 'è°ƒæŸ¥', 'æ£€å¯Ÿé™¢', 'æ³•æ²»', 'è¡Œæ”¿å¤è®®', 'ä¿¡è®¿'], 'chapter': 'æ°‘ä¸»ä¸æ³•æ²»', 'score': 85},
        {'kws': ['å›½é˜²', 'è§£æ”¾å†›', 'å†›é˜Ÿ', 'å†›äº‹', 'å†›è¥', 'å¾å…µ'], 'chapter': 'ä¸­åä¸€å®¶äº²', 'score': 80},
        {'kws': ['èˆªå¤©', 'æœˆçƒ', 'å«æ˜Ÿ', 'é£å…‰å‘ç”µ', 'ç¢³ä¸­å’Œ', 'æ–°èƒ½æº'], 'chapter': 'åˆ›æ–°é©±åŠ¨å‘å±•', 'score': 85},
        {'kws': ['ç§‘æŠ€', 'åˆ›æ–°', 'AI', 'äº’è”ç½‘', 'æ•°å­—ç»æµ'], 'chapter': 'åˆ›æ–°é©±åŠ¨å‘å±•', 'score': 75},
        {'kws': ['ç¾å›½', 'æ—¥æœ¬', 'éŸ©å›½', 'åŠ æ‹¿å¤§', 'å°å°¼', 'å›½é™…'], 'chapter': 'å»ºè®¾ç¾ä¸½ä¸­å›½', 'score': 70},
        {'kws': ['å°±ä¸š', 'å…³ç¨', 'ä¼ä¸š', 'ç»æµ', 'æ¶ˆè´¹', 'æ±½è½¦', 'å¤–è´¸'], 'chapter': 'å¯Œå¼ºä¸åˆ›æ–°', 'score': 75},
        {'kws': ['æ—…æ¸¸', 'æ–‡åŒ–', 'ç”Ÿæ´»', 'æ°‘ç”Ÿ', 'ç¤¾ä¼š'], 'chapter': 'å»ºè®¾ç¾ä¸½ä¸­å›½', 'score': 70},
        {'kws': ['äº¤é€š', 'å®‰å…¨', 'äº‹æ•…', 'ç¯å¢ƒ'], 'chapter': 'å»ºè®¾ç¾ä¸½ä¸­å›½', 'score': 72},
    ]
    
    import re
    matched = []
    for rule in rules:
        for kw in rule['kws']:
            if kw in text:
                matched.append((rule['chapter'], rule['score']))
                break
    
    # å»é‡å¹¶æŒ‰åˆ†æ•°æ’åº
    seen = set()
    result = []
    for chapter, score in sorted(matched, key=lambda x: -x[1]):
        if chapter not in seen:
            seen.add(chapter)
            result.append({'chapter': chapter, 'score': score})
    
    # åªè¿”å› >=70 åˆ†çš„
    return [r for r in result if r['score'] >= 70]

def generate_summary(content, title):
    """ç”Ÿæˆæ€»ç»“é™ˆè¿°"""
    if not content:
        return "æš‚æ— è¯¦ç»†å†…å®¹"
    
    # æå–å…³é”®å¥å­
    import re
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', content)
    important = []
    for s in sentences:
        if any(kw in s for kw in ['è¡¨ç¤º', 'æŒ‡å‡º', 'å¼ºè°ƒ', 'æ®', 'é€šè¿‡', 'å®ç°', 'è¾¾åˆ°', 'å®Œæˆ']):
            important.append(s.strip())
        if len(important) >= 2:
            break
    
    if important:
        return important[0] + 'ã€‚'
    return content[:200] + ('...' if len(content) > 200 else '')

def main():
    print("ğŸ“„ ç”Ÿæˆå¢å¼ºç‰ˆHTMLæŠ¥å‘Š...")
    
    # è¯»å–JSON
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        all_news = json.load(f)
    
    # è·å–çƒ­æ¦œæ’å
    hot_paths = get_hot_rankings()
    
    # æ’åº
    ordered_news = []
    seen_paths = set()
    
    for hot_path in hot_paths:
        for news in all_news:
            if news.get('status') != 'success':
                continue
            path = urlparse(news.get('url', '')).path
            if path == hot_path and path not in seen_paths:
                ordered_news.append(news)
                seen_paths.add(path)
                break
    
    for news in all_news:
        if news.get('status') != 'success':
            continue
        path = urlparse(news.get('url', '')).path
        if path not in seen_paths:
            ordered_news.append(news)
            seen_paths.add(path)
    
    print(f"âœ… å…± {len(ordered_news)} æ¡æ–°é—»")
    
    # ç”ŸæˆHTML
    today = datetime.now().strftime('%Y-%m-%d')
    
    html = f'''<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>é“æ³•æ—¶äº‹æŠ¥å‘Š - {today}</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{ 
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
            min-height: 100vh; padding: 20px;
        }}
        .container {{ max-width: 900px; margin: 0 auto; background: white; border-radius: 20px; box-shadow: 0 25px 80px rgba(0,0,0,0.4); overflow: hidden; }}
        .header {{ background: linear-gradient(135deg, #e94560 0%, #ff6b6b 100%); color: white; padding: 35px; text-align: center; }}
        .header h1 {{ font-size: 32px; margin-bottom: 8px; }}
        .stats {{ background: #f8f9fa; padding: 15px 30px; display: flex; gap: 30px; justify-content: center; color: #666; }}
        .content {{ padding: 30px; }}
        .date-section {{ margin-bottom: 40px; }}
        .date-header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 12px 20px; border-radius: 10px; margin-bottom: 20px; font-size: 16px; font-weight: bold; }}
        .news-item {{ background: #fff; border-radius: 16px; padding: 24px; margin-bottom: 20px; border: 1px solid #e9ecef; }}
        .news-item:hover {{ box-shadow: 0 10px 30px rgba(0,0,0,0.1); }}
        .news-header {{ display: flex; align-items: flex-start; margin-bottom: 15px; }}
        .news-rank {{ background: #e94560; color: white; width: 32px; height: 32px; border-radius: 50%; text-align: center; line-height: 32px; font-weight: bold; margin-right: 15px; flex-shrink: 0; }}
        .news-title {{ font-size: 18px; font-weight: bold; color: #1a1a2e; line-height: 1.4; }}
        .hot-tag {{ background: #ff6b6b; color: white; padding: 3px 10px; border-radius: 4px; font-size: 12px; margin-left: 10px; }}
        .news-meta {{ font-size: 13px; color: #888; margin: 10px 0; display: flex; gap: 20px; }}
        .news-content {{ background: #f8f9fa; padding: 20px; border-radius: 12px; margin: 15px 0; }}
        .content-block {{ margin-bottom: 15px; }}
        .content-block:last-child {{ margin-bottom: 0; }}
        .block-label {{ font-size: 13px; font-weight: bold; color: #e94560; margin-bottom: 8px; }}
        .content-text {{ font-size: 14px; color: #444; line-height: 1.8; }}
        .key-points {{ display: flex; flex-wrap: wrap; gap: 10px; margin-top: 10px; }}
        .key-point {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 6px 14px; border-radius: 20px; font-size: 13px; }}
        .chapter-tags {{ margin-top: 15px; }}
        .chapter-tag {{ display: inline-block; background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%); color: #155724; padding: 10px 16px; border-radius: 8px; margin-right: 10px; margin-bottom: 10px; }}
        .chapter-name {{ font-weight: bold; font-size: 14px; }}
        .chapter-core {{ font-size: 12px; margin-top: 5px; opacity: 0.8; }}
        .chapter-score {{ background: rgba(0,0,0,0.1); padding: 2px 8px; border-radius: 10px; font-size: 11px; margin-left: 8px; }}
        .footer {{ background: #f8f9fa; padding: 20px; text-align: center; color: #888; font-size: 13px; }}
        .footer a {{ color: #e94560; text-decoration: none; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“° é“æ³•æ—¶äº‹æŠ¥å‘Š</h1>
            <p>{today} Â· {len(ordered_news)}æ¡æ–°é—» Â· æ•°æ®æ¥æºï¼šä¸­å›½æ–°é—»ç½‘çƒ­æ¦œ</p>
        </div>
        <div class="stats">
            <span>ğŸ“… {datetime.now().strftime('%H:%M')} æ›´æ–°</span>
            <span>ğŸ”¥ çƒ­æ¦œæ¥æºå‰10æ¡</span>
        </div>
        <div class="content">
'''
    
    import re
    
    for i, news in enumerate(ordered_news[:20], 1):
        title = news.get('title', '')
        content = news.get('content', '')
        summary = generate_summary(content, title)
        key_points = extract_key_points(content, title)
        chapters = match_chapters(title + ' ' + content[:1000])
        
        hot_tag = '<span class="hot-tag">ğŸ”¥ çƒ­æ¦œ</span>' if i <= 10 else ''
        
        html += f'''
            <div class="news-item">
                <div class="news-header">
                    <div class="news-rank">{i}</div>
                    <div class="news-title">{title}</div>
                    {hot_tag}
                </div>
                <div class="news-meta">
                    <span>ğŸ“ {news.get("source", "ä¸­å›½æ–°é—»ç½‘")}</span>
                    <span>ğŸ“… {news.get("time", "")}</span>
                    <span>ğŸ“‚ {news.get("channel", "è¦é—»")}</span>
                </div>
                <div class="news-content">
'''
        
        # å®Œæ•´å†…å®¹
        html += f'''
                    <div class="content-block">
                        <div class="block-label">ğŸ“° æ–°é—»å†…å®¹</div>
                        <div class="content-text">{content[:500]}{"..." if len(content) > 500 else ""}</div>
                    </div>
'''
        
        # æ€»ç»“é™ˆè¿°
        html += f'''
                    <div class="content-block">
                        <div class="block-label">ğŸ“ æ€»ç»“é™ˆè¿°</div>
                        <div class="content-text">{summary}</div>
                    </div>
'''
        
        # å…³é”®è¦ç‚¹
        if key_points:
            html += '''
                    <div class="content-block">
                        <div class="block-label">ğŸ¯ å…³é”®è¦ç‚¹</div>
                        <div class="key-points">
'''
            for point in key_points:
                html += f'<span class="key-point">{point}</span>'
            html += '''
                        </div>
                    </div>
'''
        
        # è¯¾æœ¬å…³è”
        if chapters:
            html += '''
                    <div class="chapter-tags">
                        <div class="block-label">ğŸ“š è¯¾æœ¬å…³è”</div>
'''
            for ch in chapters:
                info = TEXTBOOK_DB.get(ch['chapter'], {'core': ''})
                html += f'''
                        <div class="chapter-tag">
                            <div class="chapter-name">{info['book']} Â· {ch['chapter']}<span class="chapter-score">ç›¸å…³åº¦ {ch['score']}%</span></div>
                            <div class="chapter-core">ğŸ’¡ {info['core']}</div>
                        </div>
'''
            html += '''
                    </div>
'''
        
        html += '''
                </div>
            </div>
'''
    
    html += '''
        </div>
        <div class="footer">
            <p>ğŸ¤– è‡ªåŠ¨ç”Ÿæˆ by é“æ³•æ—¶äº‹æŠ¥å‘Šç³»ç»Ÿ</p>
            <p>ğŸ”— <a href="https://www.chinanews.com.cn/importnews.html">ä¸­å›½æ–°é—»ç½‘çƒ­æ¦œ</a></p>
        </div>
    </div>
</body>
</html>'''
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write(html)
    
    print(f"\nâœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {OUTPUT_FILE}")
    print(f"ğŸ“Š å‰3æ¡é¢„è§ˆï¼š")
    for i, n in enumerate(ordered_news[:3], 1):
        chapters = match_chapters(n.get('title', '') + ' ' + n.get('content', '')[:500])
        print(f"  {i}. {n.get('title', '')[:35]}...")
        print(f"     è¯¾æœ¬: {[c['chapter'] for c in chapters]}")

if __name__ == "__main__":
    main()
