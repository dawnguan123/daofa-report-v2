#!/usr/bin/env python3
"""
ç”Ÿæˆé“æ³•æ—¶äº‹æŠ¥å‘Šï¼ˆä¸“ä¸šç‰ˆï¼‰
- è¯¦ç»†æ€»ç»“é™ˆè¿°
- æ–°é—»å†…å®¹é“¾æ¥
- é«˜ç›¸å…³åº¦è¯¾æœ¬å…³è”
"""
import requests
import json
from bs4 import BeautifulSoup
from urllib.parse import urlparse
from datetime import datetime

INPUT_FILE = "/Users/guanliming/dailynews/output/hotnews_detail.json"
OUTPUT_FILE = "/Users/guanliming/dailynews/output/report_latest.html"
BASE_URL = "https://www.chinanews.com.cn"

TEXTBOOK_DB = {
    'ä¸­åä¸€å®¶äº²': {'book': 'ä¹å¹´çº§ä¸Šå†Œ', 'core': 'ç»´æŠ¤ç¥–å›½ç»Ÿä¸€ã€æ°‘æ—å›¢ç»“æ˜¯æ¯ä¸ªå…¬æ°‘çš„è´£ä»»å’Œä¹‰åŠ¡'},
    'æ°‘ä¸»ä¸æ³•æ²»': {'book': 'ä¹å¹´çº§ä¸Šå†Œ', 'core': 'ä¾æ³•æ²»å›½æ˜¯å…šé¢†å¯¼äººæ°‘æ²»ç†å›½å®¶çš„åŸºæœ¬æ–¹ç•¥'},
    'åˆ›æ–°é©±åŠ¨å‘å±•': {'book': 'ä¹å¹´çº§ä¸Šå†Œ', 'core': 'åˆ›æ–°æ˜¯å¼•é¢†å‘å±•çš„ç¬¬ä¸€åŠ¨åŠ›'},
    'å»ºè®¾ç¾ä¸½ä¸­å›½': {'book': 'ä¹å¹´çº§ä¸Šå†Œ', 'core': 'åšæŒäººä¸è‡ªç„¶å’Œè°å…±ç”Ÿï¼Œå»ºè®¾ç¾ä¸½ä¸­å›½'},
    'å¯Œå¼ºä¸åˆ›æ–°': {'book': 'ä¹å¹´çº§ä¸Šå†Œ', 'core': 'ä»¥äººæ°‘ä¸ºä¸­å¿ƒï¼Œå®ç°å…±åŒå¯Œè£•'},
    'è¸ä¸Šå¼ºå›½ä¹‹è·¯': {'book': 'ä¹å¹´çº§ä¸Šå†Œ', 'core': 'æ”¹é©å¼€æ”¾æ˜¯å†³å®šå½“ä»£ä¸­å›½å‘½è¿çš„å…³é”®ä¸€æ‹›'},
    'æ–‡æ˜ä¸å®¶å›­': {'book': 'ä¹å¹´çº§ä¸Šå†Œ', 'core': 'ä¸­åä¼˜ç§€ä¼ ç»Ÿæ–‡åŒ–æ˜¯ä¸­åæ°‘æ—çš„ç²¾ç¥å‘½è„‰'},
    'ä¸­å›½äºº ä¸­å›½æ¢¦': {'book': 'ä¹å¹´çº§ä¸Šå†Œ', 'core': 'å®ç°ä¸­åæ°‘æ—ä¼Ÿå¤§å¤å…´æ˜¯ä¸­åæ°‘æ—è¿‘ä»£ä»¥æ¥æœ€ä¼Ÿå¤§çš„æ¢¦æƒ³'},
}

def get_hot_rankings():
    resp = requests.get(f"{BASE_URL}/importnews.html", timeout=15)
    resp.encoding = 'utf-8'
    soup = BeautifulSoup(resp.text, 'html.parser')
    hotbox = soup.find(id="zxrb")
    hot_paths = []
    if hotbox:
        next_list = hotbox.find_next_sibling()
        if next_list:
            for link in next_list.find_all('a')[:10]:
                href = link.get('href', '')
                if href.startswith('//'):
                    url = 'https:' + href
                elif href.startswith('/'):
                    url = BASE_URL + href
                else:
                    url = href
                hot_paths.append(urlparse(url).path)
    return hot_paths

def extract_summary(content, title):
    """ç”Ÿæˆä¸“ä¸šã€è¯¦ç»†çš„æ€»ç»“é™ˆè¿°"""
    if not content:
        return "è¯¥æ–°é—»æš‚æ— è¯¦ç»†æŠ¥é“å†…å®¹ã€‚"
    
    import re
    
    # æå–å…³é”®ä¿¡æ¯
    key_info = []
    
    # æ ¸å¿ƒæ•°æ®
    nums = re.findall(r'(\d+\.?\d*(?:ä¸‡|äº¿|åƒä¸‡|ç™¾ä¸‡|åƒäº¿|%)?)', content)
    if nums:
        key_info.append(f"æ•°æ®å±‚é¢ï¼Œæœ¬æ–°é—»æ¶‰åŠçš„å…³é”®æ•°å€¼åŒ…æ‹¬ï¼š{', '.join(set(nums[:3]))}")
    
    # ä¸»ä½“æœºæ„/äººç‰©
    orgs = re.findall(r'([^\s]{2,6}(éƒ¨|å§”|å±€|åŠ|æ”¿åºœ|æ³•é™¢|æ£€å¯Ÿé™¢|å…¬å¸|æœºæ„))', content)
    if orgs:
        unique_orgs = list(dict.fromkeys([o[0] for o in orgs[:2]]))
        key_info.append(f"ä¸»è¦å‚ä¸ä¸»ä½“åŒ…æ‹¬ï¼š{', '.join(unique_orgs)}")
    
    # æ—¶é—´èŠ‚ç‚¹
    dates = re.findall(r'(\d{4}å¹´\d{1,2}æœˆ(?:\d{1,2}æ—¥)?)', content)
    if dates:
        key_info.append(f"æ—¶é—´èŠ‚ç‚¹æ ‡æ³¨ä¸ºï¼š{dates[0]}")
    
    # æ”¿ç­–/æªæ–½
    measures = re.findall(r'(?:é€šè¿‡|å®æ–½|å‘å¸ƒ|åˆ¶å®š|æ¨è¿›|åŠ å¼º|å®Œå–„)([^ã€‚ï¼ï¼Ÿ]+)', content)
    if measures:
        key_info.append(f"æ ¸å¿ƒä¸¾æªæ¶µç›–ï¼š{measures[0].strip()}")
    
    # å½±å“/æ„ä¹‰
    impacts = re.findall(r'(?:ä¿ƒè¿›|æ¨åŠ¨|å®ç°|æå‡|åŠ å¼º|ä¿éšœ|ç»´æŠ¤|ç¡®ä¿)([^ã€‚ï¼ï¼Ÿ]+)', content)
    if impacts:
        key_info.append(f"é¢„æœŸæ•ˆæœæˆ–ä»·å€¼ä½“ç°åœ¨ï¼š{impacts[0].strip()}")
    
    # æ„å»ºå®Œæ•´æ€»ç»“
    summary_parts = []
    
    # åŸºç¡€èƒŒæ™¯
    if 'æ®' in content[:100]:
        source = content[:50].split('æ®')[-1].split('ã€‚')[0] if 'ã€‚' in content[:100] else ''
        if source:
            summary_parts.append(f"æ®ç›¸å…³æŠ¥é“ï¼Œ{source}ã€‚")
    
    # æ ¸å¿ƒè¦ç‚¹
    if key_info:
        summary_parts.append('ï¼›'.join(key_info))
    
    # æ•´ä½“è¯„ä»·
    if any(kw in content for kw in ['é¦–æ¬¡', 'ç¬¬ä¸€', 'å†å²', 'çªç ´', 'åˆ›æ–°']):
        summary_parts.append("è¯¥äº‹ä»¶å…·æœ‰é‡Œç¨‹ç¢‘æ„ä¹‰ï¼Œæ ‡å¿—ç€ç›¸å…³é¢†åŸŸè¿›å…¥æ–°çš„å‘å±•é˜¶æ®µã€‚")
    
    if any(kw in content for kw in ['é¢„è®¡', 'å°†', 'æœªæ¥', 'è®¡åˆ’']):
        summary_parts.append("ä»å‘å±•è¶‹åŠ¿æ¥çœ‹ï¼Œç›¸å…³å·¥ä½œæ­£åœ¨ç¨³æ­¥æ¨è¿›ä¸­ã€‚")
    
    # æ‹¼æ¥æ€»ç»“ï¼ˆé™åˆ¶å­—æ•°ï¼Œé¿å…æº¢å‡ºï¼‰
    full_summary = ' '.join(summary_parts)
    if len(full_summary) > 400:
        return full_summary[:400] + "..."
    return full_summary if full_summary else content[:200] + "..."

def match_chapters(text):
    rules = [
        {'kws': ['å°æ¹¾', 'ä¸¤å²¸', 'å°ç‹¬', 'å›½å°åŠ', 'å°æµ·', 'èµ–æ¸…å¾·'], 'chapter': 'ä¸­åä¸€å®¶äº²', 'score': 90},
        {'kws': ['åè…', 'è¿çºª', 'è¿æ³•', 'å—è´¿', 'è°ƒæŸ¥', 'æ£€å¯Ÿé™¢', 'æ³•æ²»', 'è¡Œæ”¿å¤è®®', 'ä¿¡è®¿'], 'chapter': 'æ°‘ä¸»ä¸æ³•æ²»', 'score': 85},
        {'kws': ['å›½é˜²', 'è§£æ”¾å†›', 'å†›é˜Ÿ', 'å†›äº‹', 'å†›è¥', 'å¾å…µ'], 'chapter': 'ä¸­åä¸€å®¶äº²', 'score': 80},
        {'kws': ['èˆªå¤©', 'æœˆçƒ', 'å«æ˜Ÿ', 'é£å…‰å‘ç”µ', 'ç¢³ä¸­å’Œ', 'æ–°èƒ½æº'], 'chapter': 'åˆ›æ–°é©±åŠ¨å‘å±•', 'score': 85},
        {'kws': ['ç§‘æŠ€', 'åˆ›æ–°', 'AI', 'äº’è”ç½‘', 'æ•°å­—ç»æµ'], 'chapter': 'åˆ›æ–°é©±åŠ¨å‘å±•', 'score': 75},
        {'kws': ['ç¾å›½', 'æ—¥æœ¬', 'éŸ©å›½', 'åŠ æ‹¿å¤§', 'å°å°¼', 'å›½é™…'], 'chapter': 'å»ºè®¾ç¾ä¸½ä¸­å›½', 'score': 70},
        {'kws': ['å°±ä¸š', 'å…³ç¨', 'ä¼ä¸š', 'ç»æµ', 'æ¶ˆè´¹', 'æ±½è½¦', 'å¤–è´¸'], 'chapter': 'å¯Œå¼ºä¸åˆ›æ–°', 'score': 75},
        {'kws': ['æ—…æ¸¸', 'æ–‡åŒ–', 'ç”Ÿæ´»', 'æ°‘ç”Ÿ', 'ç¤¾ä¼š'], 'chapter': 'å»ºè®¾ç¾ä¸½ä¸­å›½', 'score': 70},
        {'kws': ['äº¤é€š', 'å®‰å…¨', 'äº‹æ•…', 'ç¯å¢ƒ'], 'chapter': 'å»ºè®¾ç¾ä¸½ä¸­å›½', 'score': 72},
    ]
    
    import re
    matched = []
    for rule in rules:
        for kw in rule['kws']:
            if kw in text:
                matched.append((rule['chapter'], rule['score']))
                break
    
    seen = set()
    result = []
    for chapter, score in sorted(matched, key=lambda x: -x[1]):
        if chapter not in seen:
            seen.add(chapter)
            result.append({'chapter': chapter, 'score': score})
    
    return [r for r in result if r['score'] >= 70]

def main():
    print("ğŸ“„ ç”Ÿæˆä¸“ä¸šç‰ˆHTMLæŠ¥å‘Š...")
    
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        all_news = json.load(f)
    
    hot_paths = get_hot_rankings()
    
    ordered_news = []
    seen_paths = set()
    
    for hot_path in hot_paths:
        for news in all_news:
            if news.get('status') != 'success':
                continue
            path = urlparse(news.get('url', '')).path
            if path == hot_path and path not in seen_paths:
                ordered_news.append(news)
                seen_paths.add(path)
                break
    
    for news in all_news:
        if news.get('status') != 'success':
            continue
        path = urlparse(news.get('url', '')).path
        if path not in seen_paths:
            ordered_news.append(news)
            seen_paths.add(path)
    
    print(f"âœ… å…± {len(ordered_news)} æ¡æ–°é—»")
    
    today = datetime.now().strftime('%Y-%m-%d')
    update_time = datetime.now().strftime('%H:%M')
    
    html = f'''<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>é“æ³•æ—¶äº‹æŠ¥å‘Š - {today}</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{ 
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
            min-height: 100vh; padding: 20px;
        }}
        .container {{ max-width: 950px; margin: 0 auto; background: white; border-radius: 20px; box-shadow: 0 25px 80px rgba(0,0,0,0.4); overflow: hidden; }}
        .header {{ background: linear-gradient(135deg, #e94560 0%, #ff6b6b 100%); color: white; padding: 40px 35px; text-align: center; }}
        .header h1 {{ font-size: 36px; margin-bottom: 10px; }}
        .header p {{ font-size: 15px; opacity: 0.9; }}
        .stats {{ background: #f8f9fa; padding: 18px 35px; display: flex; gap: 40px; justify-content: center; color: #666; font-size: 14px; }}
        .content {{ padding: 35px; }}
        .news-item {{ background: #fff; border-radius: 16px; padding: 28px; margin-bottom: 25px; border: 1px solid #e9ecef; }}
        .news-header {{ display: flex; align-items: flex-start; margin-bottom: 18px; }}
        .news-rank {{ background: #e94560; color: white; width: 36px; height: 36px; border-radius: 50%; text-align: center; line-height: 36px; font-weight: bold; font-size: 16px; margin-right: 18px; flex-shrink: 0; }}
        .news-title {{ font-size: 20px; font-weight: bold; color: #1a1a2e; line-height: 1.45; }}
        .hot-tag {{ background: #ff6b6b; color: white; padding: 4px 12px; border-radius: 4px; font-size: 13px; margin-left: 12px; }}
        .news-meta {{ font-size: 14px; color: #888; margin: 12px 0; display: flex; gap: 25px; }}
        .summary-section {{ background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-radius: 12px; padding: 22px; margin: 18px 0; }}
        .summary-header {{ display: flex; align-items: center; margin-bottom: 12px; }}
        .summary-label {{ font-size: 15px; font-weight: bold; color: #e94560; display: flex; align-items: center; gap: 8px; }}
        .content-link {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 6px 16px; border-radius: 6px; font-size: 13px; text-decoration: none; margin-left: auto; }}
        .content-link:hover {{ opacity: 0.9; }}
        .summary-text {{ font-size: 15px; color: #444; line-height: 1.9; }}
        .chapter-tags {{ margin-top: 20px; }}
        .chapter-tag {{ display: inline-block; background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%); color: #155724; padding: 14px 20px; border-radius: 10px; margin-right: 15px; margin-bottom: 12px; }}
        .chapter-name {{ font-weight: bold; font-size: 15px; }}
        .chapter-core {{ font-size: 13px; margin-top: 6px; opacity: 0.85; }}
        .chapter-score {{ background: rgba(0,0,0,0.1); padding: 3px 10px; border-radius: 12px; font-size: 12px; margin-left: 10px; }}
        .footer {{ background: #f8f9fa; padding: 25px; text-align: center; color: #888; font-size: 14px; }}
        .footer a {{ color: #e94560; text-decoration: none; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“° é“æ³•æ—¶äº‹æŠ¥å‘Š</h1>
            <p>{today} Â· {len(ordered_news)}æ¡æ–°é—» Â· æ•°æ®æ¥æºï¼šä¸­å›½æ–°é—»ç½‘çƒ­æ¦œ</p>
        </div>
        <div class="stats">
            <span>ğŸ• {update_time} æ›´æ–°</span>
            <span>ğŸ”¥ çƒ­æ¦œæ¥æºå‰10æ¡ä¼˜å…ˆå±•ç¤º</span>
            <span>ğŸ“š è¯¾æœ¬å…³è”ä»…æ˜¾ç¤ºç›¸å…³åº¦â‰¥70%</span>
        </div>
        <div class="content">
'''
    
    import re
    
    for i, news in enumerate(ordered_news[:25], 1):
        title = news.get('title', '')
        content = news.get('content', '')
        url = news.get('url', '#')
        summary = extract_summary(content, title)
        chapters = match_chapters(title + ' ' + content[:1000])
        
        hot_tag = '<span class="hot-tag">ğŸ”¥ çƒ­æ¦œ</span>' if i <= 10 else ''
        
        html += f'''
            <div class="news-item">
                <div class="news-header">
                    <div class="news-rank">{i}</div>
                    <div class="news-title">{title}</div>
                    {hot_tag}
                </div>
                <div class="news-meta">
                    <span>ğŸ“ {news.get("source", "ä¸­å›½æ–°é—»ç½‘")}</span>
                    <span>ğŸ“… {news.get("time", "")}</span>
                    <span>ğŸ“‚ {news.get("channel", "è¦é—»")}</span>
                </div>
                <div class="summary-section">
                    <div class="summary-header">
                        <div class="summary-label">ğŸ“ ä¸“ä¸šæ€»ç»“</div>
                        <a href="{url}" target="_blank" class="content-link">ğŸ“° æŸ¥çœ‹åŸæ–‡è¯¦æƒ…</a>
                    </div>
                    <div class="summary-text">{summary}</div>
                </div>
'''
        
        if chapters:
            html += '''
                    <div class="chapter-tags">
'''
            for ch in chapters:
                info = TEXTBOOK_DB.get(ch['chapter'], {'core': ''})
                html += f'''
                        <div class="chapter-tag">
                            <div class="chapter-name">{info['book']} Â· {ch['chapter']}<span class="chapter-score">ç›¸å…³åº¦ {ch['score']}%</span></div>
                            <div class="chapter-core">ğŸ’¡ {info['core']}</div>
                        </div>
'''
            html += '''
                    </div>
'''
        
        html += '''
                </div>
'''
    
    html += '''
        </div>
        <div class="footer">
            <p>ğŸ¤– è‡ªåŠ¨ç”Ÿæˆ by é“æ³•æ—¶äº‹æŠ¥å‘Šç³»ç»Ÿ</p>
            <p>ğŸ”— <a href="https://www.chinanews.com.cn/importnews.html">ä¸­å›½æ–°é—»ç½‘çƒ­æ¦œ</a></p>
        </div>
    </div>
</body>
</html>'''
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write(html)
    
    print(f"\nâœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {OUTPUT_FILE}")
    print(f"\nğŸ“Š å‰3æ¡é¢„è§ˆï¼š")
    for i, n in enumerate(ordered_news[:3], 1):
        chapters = match_chapters(n.get('title', '') + ' ' + n.get('content', '')[:500])
        summary = extract_summary(n.get('content', ''), n.get('title', ''))
        print(f"\n{i}. {n.get('title', '')}")
        print(f"   æ€»ç»“ï¼š{summary[:100]}...")

if __name__ == "__main__":
    main()
