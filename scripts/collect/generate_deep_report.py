#!/usr/bin/env python3
"""
ç”Ÿæˆé“æ³•æ—¶äº‹æŠ¥å‘Šï¼ˆæ·±åº¦ç‰ˆï¼‰
- æ€»ç»“é™ˆè¿°ï¼šåŸºäºæ–‡ç« æ·±åº¦æ€»ç»“
- è¯¾æœ¬å…³è”ï¼šå®Œæ•´ç« èŠ‚è§‚ç‚¹
"""
import requests
import json
from bs4 import BeautifulSoup
from urllib.parse import urlparse
from datetime import datetime

INPUT_FILE = "/Users/guanliming/dailynews/output/hotnews_detail.json"
OUTPUT_FILE = "/Users/guanliming/dailynews/output/report_latest.html"
BASE_URL = "https://www.chinanews.com.cn"

# è¯¾æœ¬ç« èŠ‚è¯¦ç»†çŸ¥è¯†ç‚¹åº“ï¼ˆæ‰©å±•ç‰ˆï¼‰
TEXTBOOK_DB = {
    'ä¸­åä¸€å®¶äº²': {
        'book': 'ä¹å¹´çº§ä¸Šå†Œ',
        'core': 'ç»´æŠ¤ç¥–å›½ç»Ÿä¸€ã€æ°‘æ—å›¢ç»“æ˜¯æ¯ä¸ªå…¬æ°‘çš„è´£ä»»å’Œä¹‰åŠ¡',
        'points': [
            'åšæŒä¸€ä¸ªä¸­å›½åŸåˆ™æ˜¯å¤„ç†å°æ¹¾é—®é¢˜çš„æ”¿æ²»åŸºç¡€',
            'åŠ å¼ºæ°‘æ—å›¢ç»“ï¼Œç»´æŠ¤å›½å®¶ç»Ÿä¸€æ˜¯å„æ°‘æ—çš„å…±åŒæ„¿æœ›',
            'å®ç°ç¥–å›½å®Œå…¨ç»Ÿä¸€æ˜¯å…¨ä½“ä¸­åå„¿å¥³çš„å…±åŒæ„¿æœ›',
            'åšæŒ"å’Œå¹³ç»Ÿä¸€ã€ä¸€å›½ä¸¤åˆ¶"æ–¹é’ˆ',
        ]
    },
    'æ°‘ä¸»ä¸æ³•æ²»': {
        'book': 'ä¹å¹´çº§ä¸Šå†Œ',
        'core': 'ä¾æ³•æ²»å›½æ˜¯å…šé¢†å¯¼äººæ°‘æ²»ç†å›½å®¶çš„åŸºæœ¬æ–¹ç•¥',
        'points': [
            'æ³•æ²»æ˜¯äººç±»ç¤¾ä¼šè¿›å…¥ç°ä»£æ–‡æ˜çš„é‡è¦æ ‡å¿—',
            'æ³•æ²»è¦æ±‚å®è¡Œè‰¯æ³•ä¹‹æ²»å’Œå–„æ²»',
            'æ³•æ²»æ˜¯è§£å†³ç¤¾ä¼šçŸ›ç›¾ã€ç»´æŠ¤ç¤¾ä¼šç¨³å®šã€å®ç°ç¤¾ä¼šå…¬æ­£çš„æœ‰æ•ˆæ–¹å¼',
            'ä¾æ³•è¡Œæ”¿æ˜¯ä¾æ³•æ²»å›½çš„é‡è¦ç¯èŠ‚',
            'è¡Œæ”¿å¤è®®æ˜¯å…¬æ°‘ç»´æŠ¤åˆæ³•æƒç›Šçš„é‡è¦é€”å¾„',
        ]
    },
    'åˆ›æ–°é©±åŠ¨å‘å±•': {
        'book': 'ä¹å¹´çº§ä¸Šå†Œ',
        'core': 'åˆ›æ–°æ˜¯å¼•é¢†å‘å±•çš„ç¬¬ä¸€åŠ¨åŠ›',
        'points': [
            'åˆ›æ–°æ˜¯ä¸€ä¸ªæ°‘æ—è¿›æ­¥çš„çµé­‚ï¼Œæ˜¯å›½å®¶å…´æ—ºå‘è¾¾çš„ä¸ç«­åŠ¨åŠ›',
            'ç§‘æŠ€åˆ›æ–°æ˜¯æé«˜ç¤¾ä¼šç”Ÿäº§åŠ›å’Œç»¼åˆå›½åŠ›çš„æˆ˜ç•¥æ”¯æ’‘',
            'å»ºè®¾åˆ›æ–°å‹å›½å®¶ï¼Œè¦åšæŒè‡ªä¸»åˆ›æ–°ã€é‡ç‚¹è·¨è¶Š',
            'åˆ›æ–°é©±åŠ¨å‘å±•æˆ˜ç•¥æ˜¯å»ºè®¾ç°ä»£åŒ–ç»æµä½“ç³»çš„æˆ˜ç•¥æ”¯æ’‘',
            'ç§‘æŠ€å¼ºå›½æˆ˜ç•¥æ¨åŠ¨ä¸­å›½å‘ä¸–ç•Œç§‘æŠ€å¼ºå›½è¿ˆè¿›',
        ]
    },
    'å»ºè®¾ç¾ä¸½ä¸­å›½': {
        'book': 'ä¹å¹´çº§ä¸Šå†Œ',
        'core': 'åšæŒäººä¸è‡ªç„¶å’Œè°å…±ç”Ÿï¼Œå»ºè®¾ç¾ä¸½ä¸­å›½',
        'points': [
            'ç”Ÿæ€å…´åˆ™æ–‡æ˜å…´ï¼Œç”Ÿæ€è¡°åˆ™æ–‡æ˜è¡°',
            'åšæŒèŠ‚çº¦èµ„æºå’Œä¿æŠ¤ç¯å¢ƒçš„åŸºæœ¬å›½ç­–',
            'åšæŒç»¿è‰²å‘å±•ç†å¿µï¼Œèµ°ç”Ÿäº§å‘å±•ã€ç”Ÿæ´»å¯Œè£•ã€ç”Ÿæ€è‰¯å¥½çš„æ–‡æ˜å‘å±•é“è·¯',
            'æ¨åŠ¨å½¢æˆç»¿è‰²å‘å±•æ–¹å¼å’Œç”Ÿæ´»æ–¹å¼',
            'ç”Ÿæ€ç¯å¢ƒä¿æŠ¤æ˜¯åŠŸåœ¨å½“ä»£ã€åˆ©åœ¨åƒç§‹çš„äº‹ä¸š',
        ]
    },
    'å¯Œå¼ºä¸åˆ›æ–°': {
        'book': 'ä¹å¹´çº§ä¸Šå†Œ',
        'core': 'ä»¥äººæ°‘ä¸ºä¸­å¿ƒï¼Œå®ç°å…±åŒå¯Œè£•',
        'points': [
            'ä»¥äººæ°‘ä¸ºä¸­å¿ƒçš„å‘å±•æ€æƒ³æ˜¯æ–°æ—¶ä»£åšæŒå’Œå‘å±•ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰çš„æ ¹æœ¬ç«‹åœº',
            'å…±åŒå¯Œè£•æ˜¯ç¤¾ä¼šä¸»ä¹‰çš„æœ¬è´¨è¦æ±‚',
            'å…¨é¢æ·±åŒ–æ”¹é©æ˜¯æ¨è¿›ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰äº‹ä¸šçš„å¼ºå¤§åŠ¨åŠ›',
            'åšæŒå’Œå®Œå–„ç¤¾ä¼šä¸»ä¹‰åŸºæœ¬ç»æµåˆ¶åº¦',
            'æ¨åŠ¨é«˜è´¨é‡å‘å±•ï¼Œæ„å»ºæ–°å‘å±•æ ¼å±€',
        ]
    },
    'è¸ä¸Šå¼ºå›½ä¹‹è·¯': {
        'book': 'ä¹å¹´çº§ä¸Šå†Œ',
        'core': 'æ”¹é©å¼€æ”¾æ˜¯å†³å®šå½“ä»£ä¸­å›½å‘½è¿çš„å…³é”®ä¸€æ‹›',
        'points': [
            'æ”¹é©å¼€æ”¾æ˜¯å…šå’Œäººæ°‘å¤§è¸æ­¥èµ¶ä¸Šæ—¶ä»£çš„é‡è¦æ³•å®',
            'åšæŒå…šçš„é¢†å¯¼æ˜¯ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰æœ€æœ¬è´¨çš„ç‰¹å¾',
            'åšæŒå…¨é¢æ·±åŒ–æ”¹é©ï¼Œä¸æ–­æ¨è¿›å›½å®¶æ²»ç†ä½“ç³»å’Œæ²»ç†èƒ½åŠ›ç°ä»£åŒ–',
            'å¯¹å¤–å¼€æ”¾æ˜¯æˆ‘å›½çš„åŸºæœ¬å›½ç­–ï¼Œæ˜¯å›½å®¶ç¹è£å‘å±•çš„å¿…ç”±ä¹‹è·¯',
        ]
    },
    'æ–‡æ˜ä¸å®¶å›­': {
        'book': 'ä¹å¹´çº§ä¸Šå†Œ',
        'core': 'ä¸­åä¼˜ç§€ä¼ ç»Ÿæ–‡åŒ–æ˜¯ä¸­åæ°‘æ—çš„ç²¾ç¥å‘½è„‰',
        'points': [
            'ä¸­åä¼˜ç§€ä¼ ç»Ÿæ–‡åŒ–æ˜¯ä¸­åæ°‘æ—çš„ç²¾ç¥å‘½è„‰',
            'æ–‡åŒ–è‡ªä¿¡æ˜¯æ›´åŸºç¡€ã€æ›´å¹¿æ³›ã€æ›´æ·±åšçš„è‡ªä¿¡',
            'åŸ¹è‚²å’Œè·µè¡Œç¤¾ä¼šä¸»ä¹‰æ ¸å¿ƒä»·å€¼è§‚',
            'ä¼ æ‰¿ä¸­åä¼˜ç§€ä¼ ç»Ÿæ–‡åŒ–ï¼Œæ¨åŠ¨åˆ›é€ æ€§è½¬åŒ–å’Œåˆ›æ–°æ€§å‘å±•',
            'å»ºè®¾ç¤¾ä¼šä¸»ä¹‰æ–‡åŒ–å¼ºå›½',
        ]
    },
    'ä¸­å›½äºº ä¸­å›½æ¢¦': {
        'book': 'ä¹å¹´çº§ä¸Šå†Œ',
        'core': 'å®ç°ä¸­åæ°‘æ—ä¼Ÿå¤§å¤å…´æ˜¯ä¸­åæ°‘æ—è¿‘ä»£ä»¥æ¥æœ€ä¼Ÿå¤§çš„æ¢¦æƒ³',
        'points': [
            'å®ç°ä¸­åæ°‘æ—ä¼Ÿå¤§å¤å…´æ˜¯è¿‘ä»£ä»¥æ¥ä¸­åæ°‘æ—æœ€ä¼Ÿå¤§çš„æ¢¦æƒ³',
            'ä¸­å›½æ¢¦æ˜¯å›½å®¶çš„æ¢¦ã€æ°‘æ—çš„æ¢¦ï¼Œä¹Ÿæ˜¯æ¯ä¸ªä¸­å›½äººçš„æ¢¦',
            'å®ç°ä¸­å›½æ¢¦å¿…é¡»èµ°ä¸­å›½é“è·¯ã€å¼˜æ‰¬ä¸­å›½ç²¾ç¥ã€å‡èšä¸­å›½åŠ›é‡',
            'å…¨é¢å»ºæˆå°åº·ç¤¾ä¼šæ˜¯å®ç°ä¸­å›½æ¢¦çš„å…³é”®ä¸€æ­¥',
            'ä¸ºå®ç°ç¬¬äºŒä¸ªç™¾å¹´å¥‹æ–—ç›®æ ‡ã€å®ç°ä¸­å›½æ¢¦è€Œä¸æ‡ˆåŠªåŠ›',
        ]
    },
}

def get_hot_rankings():
    resp = requests.get(f"{BASE_URL}/importnews.html", timeout=15)
    resp.encoding = 'utf-8'
    soup = BeautifulSoup(resp.text, 'html.parser')
    hotbox = soup.find(id="zxrb")
    hot_paths = []
    if hotbox:
        next_list = hotbox.find_next_sibling()
        if next_list:
            for link in next_list.find_all('a')[:10]:
                href = link.get('href', '')
                if href.startswith('//'):
                    url = 'https:' + href
                elif href.startswith('/'):
                    url = BASE_URL + href
                else:
                    url = href
                hot_paths.append(urlparse(url).path)
    return hot_paths

def generate_summary(content, title):
    """æ·±åº¦æ€»ç»“ï¼šä¿ç•™å®Œæ•´å†…å®¹ï¼Œæ ¼å¼åŒ–è¾“å‡º"""
    if not content:
        return "è¯¥æ–°é—»æš‚æ— è¯¦ç»†æŠ¥é“å†…å®¹ã€‚"
    
    import re
    
    # æ¸…ç†å†…å®¹
    content = re.sub(r'\s+', ' ', content)
    content = content.strip()
    
    # é™åˆ¶æ€»é•¿åº¦ä½†ç¡®ä¿å®Œæ•´å¥å­
    if len(content) > 600:
        # åœ¨å¥å·å¤„æˆªæ–­
        last_dot = content[:600].rfind('ã€‚')
        if last_dot > 200:
            content = content[:last_dot + 1]
        else:
            content = content[:600] + "..."
    
    # æ·»åŠ é€‚å½“çš„æ¢è¡Œä»¥ä¾¿äºé˜…è¯»
    sentences = re.split(r'([ã€‚ï¼ï¼Ÿ])', content)
    formatted = []
    current = ""
    
    for i, part in enumerate(sentences):
        current += part
        if part in 'ã€‚ï¼ï¼Ÿ' and current.strip():
            # æ¸…ç†å¹¶æ·»åŠ 
            line = current.strip()
            if line and not line.endswith('...'):
                formatted.append(line)
            current = ""
    
    if current.strip():
        formatted.append(current.strip())
    
    return '<br>'.join(formatted) if formatted else content

def match_chapters(text):
    rules = [
        {'kws': ['å°æ¹¾', 'ä¸¤å²¸', 'å°ç‹¬', 'å›½å°åŠ', 'å°æµ·', 'èµ–æ¸…å¾·'], 'chapter': 'ä¸­åä¸€å®¶äº²', 'score': 90},
        {'kws': ['åè…', 'è¿çºª', 'è¿æ³•', 'å—è´¿', 'è°ƒæŸ¥', 'æ£€å¯Ÿé™¢', 'æ³•æ²»', 'è¡Œæ”¿å¤è®®', 'ä¿¡è®¿'], 'chapter': 'æ°‘ä¸»ä¸æ³•æ²»', 'score': 85},
        {'kws': ['å›½é˜²', 'è§£æ”¾å†›', 'å†›é˜Ÿ', 'å†›äº‹', 'å†›è¥', 'å¾å…µ'], 'chapter': 'ä¸­åä¸€å®¶äº²', 'score': 80},
        {'kws': ['èˆªå¤©', 'æœˆçƒ', 'å«æ˜Ÿ', 'é£å…‰å‘ç”µ', 'ç¢³ä¸­å’Œ', 'æ–°èƒ½æº', 'äººå·¥å¿ƒè„'], 'chapter': 'åˆ›æ–°é©±åŠ¨å‘å±•', 'score': 85},
        {'kws': ['ç§‘æŠ€', 'åˆ›æ–°', 'AI', 'äº’è”ç½‘', 'æ•°å­—ç»æµ'], 'chapter': 'åˆ›æ–°é©±åŠ¨å‘å±•', 'score': 75},
        {'kws': ['ç¾å›½', 'æ—¥æœ¬', 'éŸ©å›½', 'åŠ æ‹¿å¤§', 'å°å°¼', 'å›½é™…'], 'chapter': 'å»ºè®¾ç¾ä¸½ä¸­å›½', 'score': 70},
        {'kws': ['å°±ä¸š', 'å…³ç¨', 'ä¼ä¸š', 'ç»æµ', 'æ¶ˆè´¹', 'æ±½è½¦', 'å¤–è´¸'], 'chapter': 'å¯Œå¼ºä¸åˆ›æ–°', 'score': 75},
        {'kws': ['æ—…æ¸¸', 'æ–‡åŒ–', 'ç”Ÿæ´»', 'æ°‘ç”Ÿ', 'ç¤¾ä¼š'], 'chapter': 'å»ºè®¾ç¾ä¸½ä¸­å›½', 'score': 70},
        {'kws': ['äº¤é€š', 'å®‰å…¨', 'äº‹æ•…', 'ç¯å¢ƒ'], 'chapter': 'å»ºè®¾ç¾ä¸½ä¸­å›½', 'score': 72},
        {'kws': ['æ”¹é©', 'å¼€æ”¾', 'å‘å±•'], 'chapter': 'è¸ä¸Šå¼ºå›½ä¹‹è·¯', 'score': 72},
        {'kws': ['æ–‡åŒ–', 'ä¼ ç»Ÿ', 'æ–‡æ˜'], 'chapter': 'æ–‡æ˜ä¸å®¶å›­', 'score': 70},
        {'kws': ['å¤å…´', 'æ¢¦æƒ³', 'å¼ºå›½'], 'chapter': 'ä¸­å›½äºº ä¸­å›½æ¢¦', 'score': 75},
    ]
    
    matched = []
    for rule in rules:
        for kw in rule['kws']:
            if kw in text:
                matched.append((rule['chapter'], rule['score']))
                break
    
    seen = set()
    result = []
    for chapter, score in sorted(matched, key=lambda x: -x[1]):
        if chapter not in seen:
            seen.add(chapter)
            result.append({'chapter': chapter, 'score': score})
    
    return [r for r in result if r['score'] >= 80]

def main():
    print("ğŸ“„ ç”Ÿæˆæ·±åº¦ç‰ˆHTMLæŠ¥å‘Š...")
    
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        all_news = json.load(f)
    
    hot_paths = get_hot_rankings()
    
    ordered_news = []
    seen_paths = set()
    
    for hot_path in hot_paths:
        for news in all_news:
            if news.get('status') != 'success':
                continue
            path = urlparse(news.get('url', '')).path
            if path == hot_path and path not in seen_paths:
                ordered_news.append(news)
                seen_paths.add(path)
                break
    
    for news in all_news:
        if news.get('status') != 'success':
            continue
        path = urlparse(news.get('url', '')).path
        if path not in seen_paths:
            ordered_news.append(news)
            seen_paths.add(path)
    
    print(f"âœ… å…± {len(ordered_news)} æ¡æ–°é—»")
    
    today = datetime.now().strftime('%Y-%m-%d')
    update_time = datetime.now().strftime('%H:%M')
    
    html = f'''<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>é“æ³•æ—¶äº‹æŠ¥å‘Š - {today}</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{ 
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
            min-height: 100vh; padding: 20px;
        }}
        .container {{ max-width: 950px; margin: 0 auto; background: white; border-radius: 20px; box-shadow: 0 25px 80px rgba(0,0,0,0.4); overflow: hidden; }}
        .header {{ background: linear-gradient(135deg, #e94560 0%, #ff6b6b 100%); color: white; padding: 40px 35px; text-align: center; }}
        .header h1 {{ font-size: 36px; margin-bottom: 10px; }}
        .header p {{ font-size: 15px; opacity: 0.9; }}
        .stats {{ background: #f8f9fa; padding: 18px 35px; display: flex; gap: 40px; justify-content: center; color: #666; font-size: 14px; }}
        .content {{ padding: 35px; }}
        .news-item {{ background: #fff; border-radius: 16px; padding: 28px; margin-bottom: 25px; border: 1px solid #e9ecef; }}
        .news-header {{ display: flex; align-items: flex-start; margin-bottom: 18px; }}
        .news-rank {{ background: #e94560; color: white; width: 36px; height: 36px; border-radius: 50%; text-align: center; line-height: 36px; font-weight: bold; font-size: 16px; margin-right: 18px; flex-shrink: 0; }}
        .news-title {{ font-size: 20px; font-weight: bold; color: #1a1a2e; line-height: 1.45; }}
        .hot-tag {{ background: #ff6b6b; color: white; padding: 4px 12px; border-radius: 4px; font-size: 13px; margin-left: 12px; }}
        .news-meta {{ font-size: 14px; color: #888; margin: 12px 0; display: flex; gap: 25px; }}
        .summary-section {{ background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-radius: 12px; padding: 22px; margin: 18px 0; }}
        .summary-header {{ display: flex; align-items: center; margin-bottom: 14px; }}
        .summary-label {{ font-size: 16px; font-weight: bold; color: #e94560; display: flex; align-items: center; gap: 8px; }}
        .content-link {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 7px 18px; border-radius: 6px; font-size: 13px; text-decoration: none; margin-left: auto; }}
        .content-link:hover {{ opacity: 0.9; }}
        .summary-text {{ font-size: 15px; color: #444; line-height: 1.95; }}
        .chapter-section {{ margin-top: 20px; }}
        .chapter-header {{ font-size: 16px; font-weight: bold; color: #28a745; margin-bottom: 14px; display: flex; align-items: center; gap: 8px; }}
        .chapter-tag {{ display: block; background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%); color: #155724; padding: 18px 22px; border-radius: 10px; margin-bottom: 14px; }}
        .chapter-book {{ font-weight: bold; font-size: 15px; margin-bottom: 8px; }}
        .chapter-core {{ font-size: 14px; font-weight: 600; color: #0d6e34; margin-bottom: 10px; }}
        .chapter-points {{ font-size: 13px; color: #444; line-height: 1.8; }}
        .chapter-points li {{ margin-bottom: 6px; margin-left: 18px; }}
        .chapter-score {{ background: rgba(0,0,0,0.1); padding: 3px 10px; border-radius: 12px; font-size: 12px; margin-left: 10px; }}
        .footer {{ background: #f8f9fa; padding: 25px; text-align: center; color: #888; font-size: 14px; }}
        .footer a {{ color: #e94560; text-decoration: none; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“° é“æ³•æ—¶äº‹æŠ¥å‘Š</h1>
            <p>{today} Â· {len(ordered_news)}æ¡æ–°é—» Â· æ•°æ®æ¥æºï¼šä¸­å›½æ–°é—»ç½‘çƒ­æ¦œ</p>
        </div>
        <div class="stats">
            <span>ğŸ• {update_time} æ›´æ–°</span>
            <span>ğŸ”¥ çƒ­æ¦œæ¥æºå‰10æ¡ä¼˜å…ˆå±•ç¤º</span>
            <span>ğŸ“š è¯¾æœ¬å…³è”ä»…æ˜¾ç¤ºç›¸å…³åº¦â‰¥70%</span>
        </div>
        <div class="content">
'''
    
    import re
    
    for i, news in enumerate(ordered_news[:25], 1):
        title = news.get('title', '')
        content = news.get('content', '')
        url = news.get('url', '#')
        summary = generate_summary(content, title)
        chapters = match_chapters(title + ' ' + content[:1000])
        
        hot_tag = '<span class="hot-tag">ğŸ”¥ çƒ­æ¦œ</span>' if i <= 10 else ''
        
        html += f'''
            <div class="news-item">
                <div class="news-header">
                    <div class="news-rank">{i}</div>
                    <div class="news-title">{title}</div>
                    {hot_tag}
                </div>
                <div class="news-meta">
                    <span>ğŸ“ {news.get("source", "ä¸­å›½æ–°é—»ç½‘")}</span>
                    <span>ğŸ“… {news.get("time", "")}</span>
                    <span>ğŸ“‚ {news.get("channel", "è¦é—»")}</span>
                </div>
                <div class="summary-section">
                    <div class="summary-header">
                        <div class="summary-label">ğŸ“ æ€»ç»“é™ˆè¿°</div>
                        <a href="{url}" target="_blank" class="content-link">ğŸ“° æŸ¥çœ‹åŸæ–‡è¯¦æƒ…</a>
                    </div>
                    <div class="summary-text">{summary}</div>
                </div>
'''
        
        if chapters:
            html += '''
                <div class="chapter-section">
                    <div class="chapter-header">ğŸ“š è¯¾æœ¬å…³è”</div>
'''
            for ch in chapters:
                info = TEXTBOOK_DB.get(ch['chapter'], {'core': '', 'points': []})
                html += f'''
                    <div class="chapter-tag">
                        <div class="chapter-book">{info['book']} Â· {ch['chapter']}<span class="chapter-score">ç›¸å…³åº¦ {ch['score']}%</span></div>
                        <div class="chapter-core">æ ¸å¿ƒè§‚ç‚¹ï¼š{info['core']}</div>
                        <ul class="chapter-points">
'''
                for point in info['points'][:3]:
                    html += f'<li>{point}</li>'
                html += '''
                        </ul>
                    </div>
'''
            html += '''
                </div>
'''
        
        html += '''
            </div>
'''
    
    html += '''
        </div>
        <div class="footer">
            <p>ğŸ¤– è‡ªåŠ¨ç”Ÿæˆ by é“æ³•æ—¶äº‹æŠ¥å‘Šç³»ç»Ÿ</p>
            <p>ğŸ”— <a href="https://www.chinanews.com.cn/importnews.html">ä¸­å›½æ–°é—»ç½‘çƒ­æ¦œ</a></p>
        </div>
    </div>
</body>
</html>'''
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write(html)
    
    print(f"\nâœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {OUTPUT_FILE}")
    print(f"\nğŸ“Š ç¬¬1æ¡é¢„è§ˆï¼š")
    n = ordered_news[0]
    print(f"æ ‡é¢˜: {n.get('title', '')}")
    print(f"\næ€»ç»“é™ˆè¿°ï¼ˆå‰200å­—ï¼‰:\n{generate_summary(n.get('content', ''), n.get('title', ''))[:200]}...")

if __name__ == "__main__":
    main()
